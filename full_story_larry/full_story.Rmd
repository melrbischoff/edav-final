---
title: "Full Story - Markdown Edition"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(GGally)
library(ggthemes)
library(ggridges)
library(RCurl)
library(scales)
library(latex2exp)
```

## I. Introduction

Climate change is a big problem. Like, a really big problem. According to the World Health Organization, climate change is already estimated to [kill over 150,000 people every year](https://www.who.int/heli/risks/climate/climatechange/en/), and it is a virtual guarantee that the situation [will worsen](https://climate.nasa.gov/effects/). Naturally, the conversation around this catastrophe is often through a very large lens. "Will the United States rejoin the Paris Climate Agreement?" "Does it even matter if China and India's greenhouse gas emissions continue at these rates?" We've all heard these narratives and understand their importance. To the extent that climate change is discussed, these big picture items dominate the public discourse. This singular focus on the enormity of the challenge we face is an equally enormous mistake.


Large scale introduces strong friction, and as such these points of discussion are often unwieldy and frustratingly unproductive. The public has been having this big idea discussion - again, to the extent that it has been having any serious discussion regarding climate change - for decades. Our progress towards solutions has been minimal. Perhaps it is time for a different a tact. Perhaps it is time to think small.

While national and global action capture the imagination, local progress represents an arena for real, steady gains in this struggle. If we all refocused some of our attention on the ways in which our closest communities could contribute to a solution, specific, concrete strategies would lead to legitimate gains. Get enough grains of sand, and you have a mound. Do so quickly, and you can build a dune.

To be clear - climate change will require continued attention on the aforementioned big picture problems. A global crisis requires global solutions, and we in no way advocate for abandoning these discussions. But, we have to start somewhere. And we have to start now. Local action can grant greater autonomy to individuals, offer proof of concept for larger-scale solutions that will be necessary, and bring swifter advancement. Parallel tracks of focus will be necessary moving forward.

So, in attempt to make immediate progress on an immediate problem, we encourage readers to think local. As New Yorkers, we will focus our paper on New York City (you know a problem is tremendous when New York constitutes small) and New York State. Specifically, we aim to take stock of how sustainable an area New York is currently, identify areas for improvement among private citizens and through public policy, and to explore ways in which these arenas can interact. We begin with an overview of publicly available information on the topic.



## II. Data Sources
```{r include=F}
library(readxl)
# https://data.ny.gov/Energy-Environment/Greenhouse-Gas-Emissions-From-Fuel-Combustion-Mill/djfn-trk4
emissions_from_fuel_data = read.csv("ev_data_sets/Greenhouse_Gas_Emissions_From_Fuel_Combustion__Million_Metric_Tons__Beginning_1990.csv")

# # https://data.cityofnewyork.us/Environment/Inventory-of-New-York-City-Greenhouse-Gas-Emission/w5he-u64t
# greenhouse_emissions_data = read.csv("ev_data_sets/nys/Inventory_of_New_York_City_Greenhouse_Gas_Emissions_-_Electricity_Emission_Factors__2005-2016_.csv")

# https://data.cityofnewyork.us/Environment/Inventory-of-New-York-City-Greenhouse-Gas-Emission/9jf7-zn7b
fuel_emission_factors_data = read.csv("ev_data_sets/nys/Inventory_of_New_York_City_Greenhouse_Gas_Emissions_-_Fuel_Emission_Factors__2016_.csv")

# https://data.ny.gov/Energy-Environment/NY-Clean-Energy-Dashboard-Programs-Progress-and-Pl/3rux-yyd9
energy_programs_data = read.csv("ev_data_sets/nys/NY_Clean_Energy_Dashboard_Programs_Progress_and_Plans__Beginning_January_2016.csv")

# global electric car sales
global_electric_car_sales_data = read.csv("ev_data_sets/global-electric-car-sales-by-key-markets-2010-2020.csv")

# EValuate NY data
# https://www.nyserda.ny.gov/All-Programs/Programs/ChargeNY/Support-Electric/Data-on-Electric-Vehicles-and-Charging-Stations

# EV registrations in NY (zip code, car model, dates)
ev_registrations_data = read.csv("ev_data_sets/nys/ny_ev_registrations.csv")

# https://data.ny.gov/Energy-Environment/Electric-Vehicle-Charging-Stations-in-New-York/7rrd-248n
ev_charging_data = read.csv("ev_data_sets/nys/Electric_Vehicle_Charging_Stations_in_New_York.csv")

# https://data.ny.gov/Energy-Environment/NYSERDA-Electric-Vehicle-Drive-Clean-Rebate-Data-B/thd2-fu8y
clean_rebate_data = read.csv("ev_data_sets/nys/NYSERDA_Electric_Vehicle_Drive_Clean_Rebate_Data__Beginning_2017.csv")
    
read_excel_sheets <- function(filename, tibble = FALSE) {
    sheets <- readxl::excel_sheets(filename)
    x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
    if(!tibble) x <- lapply(x, as.data.frame)
    names(x) <- sheets
    x
}

resources_sheets <- read_excel_sheets("ev_data_sets/nys/resources.xlsx")
ev_registration_tables_sheets <- read_excel_sheets("ev_data_sets/nys/EV-Registration-Tables.xlsx")
evaulate_ny_sheets <- read_excel_sheets("ev_data_sets/nys/EValuateNY.xlsx")

df_rec <- read_csv("Recycling_Diversion_and_Capture_Rates.csv")
df_build_energy <- read_csv("Energy_and_Water_Data_Disclosure_for_Local_Law_84_2020__Data_for_Calendar_Year_2019_.csv")
df_zips <- read.csv("nyc_zip_borough_neighborhoods_pop.csv")
df_area_full <- read_csv("Primary_Land_Use_Tax_Lot_Output__PLUTO_.csv")
```

On the city level, our key data source is NYC Open Data - [located here](https://opendata.cityofnewyork.us/). This site offers a library of datasets filled with municipal-government-agency-collected data. 

To begin, we wanted to understand how well NYC recycles, so we turned to a simple [recycling diversion and capture dataset](https://data.cityofnewyork.us/Environment/Recycling-Diversion-and-Capture-Rates/gaq9-z3hz). The data shows diversion and capture rates (as well as a breakout of the latter) for each zone and district in each borough for each month of 2019. It has approximately 2,800 observations.

In order to take stock of current emission factors, we rely mostly on two key datasets. First, we use an [inventory of sources of greenhouse gas emissions from fuel emissions in NYC](https://data.cityofnewyork.us/Environment/Inventory-of-New-York-City-Greenhouse-Gas-Emission/9jf7-zn7b). The most crucial variables available are sector (e.g. natural gas, propane), source (e.g. stationary, on-road mobile) and CO$_2$ emission rates. Due to the grouped nature of the data, the set itself is quite manageable, with only 24 observations. 

The second key dataset for understanding New York City greenhouse gas emissions contains [energy and water disclose data](https://data.cityofnewyork.us/Environment/Energy-and-Water-Data-Disclosure-for-Local-Law-84-/qb3v-bbre) for buildings - specifically, buildings covered by [local law 84](https://www1.nyc.gov/assets/buildings/local_laws/ll84of2009.pdf). The dataset contains variables such as zip code, BBL (a uniuqe property identifier), total square footage, kilowatt hours of electricity consumed and total metric tons of greenhouse gas emissions for buildings. The set has approximately 29,000 observations. One immediately apparent issue was the presence of negative GHG emissions for one observation. It seems to be an obvious error and is filtered out. Further Issues regarding the data will be discussed in relation to a second dataset, as well as in section III and IV.

Also crucial for understanding New York City buildings was a [primary land use dataset](https://data.cityofnewyork.us/City-Government/Primary-Land-Use-Tax-Lot-Output-PLUTO-/64uk-42ks), which also contained BBL and key building measurements for understanding 2D square footage of buildings (i.e. square footage on a single floor). This dataset has over 850,000 obvservations. This highlights a key shortcoming of the preceding dataset referenced, as it offers only a limited sample of buildings documented. Further, it is far from a random sample, as Local Law 84 covers buildings only reaching specific thresholds of square footage. In order to consider the city as a whole, the energy use dataset has to be used in order to make estimations more widely.

Lastly, we also made use of a [non-Open-NYC dataset](https://data.beta.nyc/en/dataset/pediacities-nyc-neighborhoods/resource/7caac650-d082-4aea-9f9b-3681d568e8a5) to access its variables mapping zip codes to boroughs. It has 177 entries. 

On the state level, we rely on the state-level counterpart to Open NYC [data.ny.gov](https://data.ny.gov/). This site offers a similar depth and breadth of datasets available. For our purposes, it was particularly useful for understanding the current state of vehicle usage (e.g. greenhouse gas emissions from cars, how many electric vehicles are in circulation, etc.). 

Firstly, we make use of data on [greenhouse gas emissions from fuel combustion](https://data.ny.gov/Energy-Environment/Greenhouse-Gas-Emissions-From-Fuel-Combustion-Mill/djfn-trk4). This dataset is very similar to the city-level one, variables representing metric tons of greenhouse gas emissions from sources such as residential, transportation and commercial activity, with the added benefit of a longer time period represented by the year variable. It is also of similar size to the previous set, 27 observation. This dataset is state-level but also crucial for understanding the city-level data we had, as it demonstrated key contrasts between the city and state. 

From here, we relied heavily on NYSERDA data - a subset of the entire state's data library dedicated to understanding energy research and development. 

Of initial interest is a provided dataset on the state's [status in clean energy programs](https://data.ny.gov/Energy-Environment/NY-Clean-Energy-Dashboard-Programs-Progress-and-Pl/3rux-yyd9). We use this dataset's variables such as program name, direct participants acquisitions planned, and direct participants acquired to date in order to the planned scale and current effectiveness of the state's electric vehicle rebate program. The set has approximately 23,000 observations. 

In concert with the previous dataset listed, we also used one dedicated to [the clean rebate program](https://data.ny.gov/Energy-Environment/NYSERDA-Electric-Vehicle-Drive-Clean-Rebate-Data-B/thd2-fu8y). This dataset has variables such make, model, rebate, and zip code. While the previous dataset was crucial for understanding overall program effectiveness, this one gives a more granular view and provides insights into where and how the program is or is not working. It has approximately 37,000 observations.

Lastly, while our focus was local, benchmarking is important. As such, we made use of [global electric vehicle data](https://cleanvehiclerebate.org/eng/rebate-statistics) in order to provide insights into how we are pacing in terms of EV use growth.
NOTE - IDK HOW THIS WAS USED FOR GLOBAL, CHECK WITH MELISSA.

## III. Data transformation

To begin, much of our key electric vehicle data was formatted with inconvenient variable names, so we made use of a custom function to reformat them into more usable forms. In addition, we formatted date data and made use of a combination of piping and grouping to get counts for rebates:

```{r message = F, warning= F}
library(tidyverse)
library(base)
library(zoo)
library(lubridate)

# from resources.xlsx
ev_charging_use_data = resources_sheets$`Charging Use`

# use clean_rebate_data instead - more up to date but same thing
# ev_rebate_data = resources_sheets$`Drive Clean Rebate`

# from EV-Registration-Tables.xlsx
ev_zip_code_data = ev_registration_tables_sheets$`Current by ZIP Code`
ev_make_model_data = ev_registration_tables_sheets$`Current by Make-Model`
ev_county_data = ev_registration_tables_sheets$`Current by County`
ev_over_time_data = ev_registration_tables_sheets$`Original Over Time`
ev_make_over_time = ev_registration_tables_sheets$`Original by Make`

cleanCols <- function(x){
  lower_names = tolower(names(x))
  sub_periods = gsub("\\.", "_", lower_names)
  sub_spaces = gsub(" ","_",sub_periods)
  clean_df_cols = gsub("__","_",sub_spaces)
  return(clean_df_cols)
}

names(global_electric_car_sales_data) = cleanCols(global_electric_car_sales_data)
names(energy_programs_data) = cleanCols(energy_programs_data)
names(emissions_from_fuel_data) = cleanCols(emissions_from_fuel_data)
names(fuel_emission_factors_data) = cleanCols(fuel_emission_factors_data)
names(clean_rebate_data) = cleanCols(clean_rebate_data)
names(ev_registrations_data) = cleanCols(ev_registrations_data)
#names(federal_cvrp_stats) = cleanCols(federal_cvrp_stats)
#NOTE - IDK WHAT IS GOING ON WITH CVRP LARRIES
#names(ev_rebate_data) = cleanCols(ev_rebate_data)
#NOTE - I DON'T SEE AN EV REBATE LARRY IN THE DATA SECTIONS

# ev_original_registrations_data = filter(ev_registrations_data, registration == 'Original')

clean_rebate_data$date = as.Date(clean_rebate_data$submitted_date, "%m/%d/%Y")
clean_rebate_data$year = format(clean_rebate_data$date, format="%Y")
clean_rebate_data$year_quarter <- as.yearqtr(clean_rebate_data$date, format = "%Y-%m-%d")

clean_rebate_data$cumulative_rebate_amount = cumsum(clean_rebate_data$rebate_amount_usd_)

# count by quarter
clean_rebate_counts = clean_rebate_data %>% group_by(year_quarter) %>% tally()

# by quarter
clean_rebate_data_by_quarter = aggregate(clean_rebate_data$rebate_amount_usd_,
                                         by=list(clean_rebate_data$year_quarter),
                                         FUN=sum)
#IDK WHY BUT YEAR_QUARTER WAS LOSING ITS NAME - ADDING HERE
clean_rebate_data_by_quarter$year_quarter = clean_rebate_data_by_quarter$`Group.1`
clean_rebate_data_by_quarter$rebate_amount = clean_rebate_data_by_quarter$x

clean_rebate_data_by_quarter$cumulative_rebate_amount = cumsum(clean_rebate_data_by_quarter$rebate_amount)
#SEEING A WEIRD ERROR ABOUT "REPLACEMENT HAS 0 ROWS, DATAS 17 CALLS
clean_rebate_data_by_quarter$count = clean_rebate_counts$n
```

Next, we reshape our recycling data to be grouped by borough, using the median zone rates to represent the typical for each borough. We also create a second month variable for ease of access.

```{r}
df_rec$month  = df_rec$`Month Name`
rec_use <- df_rec[c(1, 10, 7, 8, 9, 6)]

rec_use <- rec_use %>% group_by(Zone, month) %>% 
  summarise(capture_rate = median(`Capture Rate-Total ((Total Recycling - Leaves (Recycling)) / (Max Paper + Max MGP))x100`),
            paper_rate = median(`Capture Rate-Paper (Total Paper / Max Paper)`),
            mgp_rate = median(`Capture Rate-MGP (Total MGP / Max MGP)`),
            diversion_rate = median(`Diversion Rate-Total (Total Recycling / Total Waste)`))


rec_use$month <- factor(rec_use$month, levels = c("January", "February", "March", "April",
                                                  "May", "June", "July", "August", "September",
                                                  "November", "December"))
```
Further, the key dataset used for NYC building energy usage was missing key data. Specifically, not all observations had the borough field populated, and it had nothing on the previously mentioned 2D square footage. As such, the first step in our data transformation was merging the dataset with the zip-boroughs mapping (df_zips, trimmed to be only zip and borough) and land-use datasets (df_area_full) in order to access this desired information:

```{r echo = T, message = F, warning = F}

df_zips <- df_zips[c(1, 2)]


df_area_full$building_area = df_area_full$bldgfront * df_area_full$bldgdepth 
df_area <- df_area_full[c(69, 100)]

df_build_energy$zip <- df_build_energy$`Postal Code`
df_build_energy <- merge(df_build_energy, df_zips, by = "zip")

df_build_energy <- merge(x = df_build_energy, y = df_area, by.x = "BBL - 10 digits", by.y = "bbl")
```

In addition, the key greenhouse gas (ghg) field had to be converted to a numeric for manipulation and interpretation. After this, we reshaped the data for further by grouping by borough and zip code and taking both the mean and median GHG emissions for each. As previously noted, a singul negative value for GHG emissions was found. It is filtered out here, as well.

```{r echo = T, message = F, warning = F}
df_build_energy$ghg <- as.numeric(df_build_energy$`Total GHG Emissions (Metric Tons CO2e)`)
df_build_energy = filter(df_build_energy, ghg >= 0) 

df_ghg <- df_build_energy %>% group_by(borough, zip) %>% summarise(avg_ghg = mean(ghg),
                                                                                                       median_ghg = median(ghg))
df_ghg$place <- paste(df_ghg$borough, df_ghg$zip, sep = " - ")
```

## IV. Missing Values

First, there are many observations in the recycling dataset with the month field not populated. As the problem appears about the occur uniformly across boroughs and zones, we have opted to simply show the NA data in our later graph.

As mentioned previously, the borough field was not populated for most observations in the key building energy use dataset, as shown below:

```{r include = FALSE}
df_build_energy_w_nas <- read_csv("Energy_and_Water_Data_Disclosure_for_Local_Law_84_2020__Data_for_Calendar_Year_2019_.csv")

ggplot(df_build_energy_w_nas, aes(Borough)) +
  geom_bar(stat = "count") +
  ggtitle("Most Observations Have No Borough Documented") +
  ylab("Observations") + 
  scale_y_continuous(label = comma)
```

The solution for this missing data was discussed previously.

In addition,

```{r}
#sum(is.na(energy_efficiency_project_data$*CO2 col*))
#^^THIS MAKES MARKDOWN BARF
```

## V. Results


We begin our analysis with a basic measure of how much a community cares about the environment - how well it recycles.Specifically, we consider the diversion rate (recycled waste/total waste) of every Zone (a subgroup of a borough) documented. Unfortunately, New York City is very lacking in this measure.

```{r echo = F}
ggplot(rec_use, aes(x = month, y = diversion_rate, group = Zone)) +
  geom_line(aes(color = Zone)) +
  scale_color_colorblind() +
  xlab("Month") +
  ylab("Typical Overall Diversion Rate - %") +
  geom_hline(yintercept = 43.2)+
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

Notice the flat horizontal line above the others. This is not marking the diversion rate for an NYC Zone - it is a comparison point. Specifically, it the 2019 diversion rate for [Virginia](https://www.deq.virginia.gov/land-waste/recycling/recycling-data/recycling-rate-report). Obviously every zone in the city is falling well short of this standard. 

It should be noted that a city and state may have different obstacles for their recycling; however, it should also be noted that NYC and VA are virtually the same size. New York's population is only 200,000 people fewer than Virginia's [according to the census bureau's website](https://www.census.gov/quickfacts/fact/table/VA,newyorkcitynewyork/PST045219). Further, New York is one of the most well-resourced cities in the world. Simply put, we should not be falling this short. Several municipalities in Virginia have implemented single stream recycling, and the state as a whole is now outperforming. Perhaps such a policy could help.

While recycling stood out as an easy entrance point to understanding New York's current sustainability, this is, of course, a very incomplete picture. We next decided to consider perhaps the most important measure of an area's environmental impact = Greenhouse Gas Emissions (GHG). 

We begin by considering the largest sources of GHG in New York State over time:

```{r echo = F, message = F, warning=F}
library("tidyverse")
library(ggplot2)

emissions_from_fuel_data_df <- emissions_from_fuel_data %>%
  select(year, residential_total, commercial_total, industrial_total,
         transportation_total, electric_generation_total,
         net_imports_of_electricity) %>%
  gather(key = "variable", value = "value", -year)

ggplot(emissions_from_fuel_data_df, aes(x = year, y = value)) + 
  geom_line(aes(color = variable)) +
  geom_point(size = 1, color = "darkgray") +
  scale_color_manual(values=c("grey", "grey", "grey", "grey", "grey", "red")) +
  scale_color_discrete(name = "GHG Source", labels = c("Commercial", "Electric Generation", "Industrial","Net Imports of Electricity", "Residential", "Transportation")) +
ggtitle("New York State GHG Emissions by Source") +
  xlab("Year") +
  ylab("Million Metric Tons of GHG")

```

The elevated levels of emissions caused by transportation immediately jump out. This suggests that cars, trucks, and other motor vehicles are some of the biggest local culprits.

Interestingly, this pattern does not fully hold when considering just New York City, as stationary fuel burners represent a larger problem here:

# TODO this is hideous
#TODO - WE SHOULD ACTUALLY ADD UP STATIONARY SHIT IN THE FIRST ONE (E.G. RESIDENTIAL, INDUSTRIAL, AND MAKE SURE THIS IS ACTUALLY A BIG DIFF)
```{r fig.width=10, echo = F}
ggplot(fuel_emission_factors_data, aes(x=source, y=co2e_kg_unit__fossil_, fill=sector)) +
  geom_bar(stat="identity") +
  scale_fill_discrete(name = "GHG Source", labels = c("#2 Fuel Oil (Buildings)", "#2 Fuel Oil (Industrial)", "#4 Fuel Oil (Buildings)","#4 Fuel Oil (Industrial)", "#6 Fuel Oil (Buildings)", "#6 Fuel Oil (Industrial)", "Aviation Gasoline", "Biodiesel - Heavy Duty Trucks", "Biodiesel - Biogenic Carbon", "CNG - Buses", "Diesel - Bus", "Diesel - Heavy Duty Vehicles", "Diesel - Light Trucks", "Diesel - Marine (In Port)", "Diessel - Rail Locomotive", "Diesel Passenger Cars", "Ethanol (E100) - Passenger Car", "Gasoline - Light Trucks", "Gasoline - Passenger Cars", "Jet Fuel", "Kerosene", "Natural Gas (Buildings)","Natural Gas - Industrial", "Propane")) +
ggtitle("New York State GHG Emissions by Source") +
  xlab("Source") +
  ylab("IDK What These Are LOL") +
  theme_grey(16)
  
```

Here, it is important to note two crucial limitations of our data. Firstly, the data set for NYC emissions only represents 1 year - 2016. It is possible that we were unlucky, and this is an outlier. Secondly, NYC Open Data does provide methodology for measurement. This is quite important for this particular question. New York is a city with many commuters, and it is unclear if emissions from cars driven by people who do not live in the city but work in it are included. 

Still, caveats aside, the dip in the importance of transportation (IS THER ONE???) does coincide with zooming in on a city that prioritizes walking and public transportation, suggesting that commuter driving may be a very important subgset of transportation emissions.

On the other hand, the plot also demonstrates the clear importance of buildings when considering the city's GHG emissions, warranting a closer look at building emissions in the city. As a first step, we consider the locations of our worst emitters:

```{r fig.height = 20, echo=FALSE}
ggplot(df_ghg, aes(x = avg_ghg, y = fct_reorder(place, avg_ghg))) +
  geom_point() +
  xlab("Metric Tons of GHG Emissions per Building") +
  ylab("Borough - Zip Code") +
  scale_x_continuous(label = comma) +
  theme_grey(16) 
  

```

While the 11370 zip code in Queens stands out as a particularly high emitter, Manhattan appears to be the borough with the most highly damaging buildings.

Of equal value is a better understanding of the types of buildings that are most often responsible for high emissions - shown below. Prior to considering the graph, we note that results here are filtered. Specifically, we considering only buildings with GHG emissions of 2,952 metric tons or fewer. This threshold was landed on after several rounds of graphing made it clear that anything above this threshold skewed the graph in such a way as to make it difficult to read. The buildings kept represent over 96% of all observations. 

```{r fig.height=20, fig.width=15, echo=FALSE, message = F}
ggplot(filter(df_build_energy, ghg <= 2952), aes(x = ghg, y = `Primary Property Type - Self Selected`, group = `Primary Property Type - Self Selected`, fill = `Primary Property Type - Self Selected`)) +
  geom_density_ridges() +
  theme_ridges() +
  theme(legend.position = "none") +
  scale_x_continuous(label = comma, breaks = seq(from = 0, to = 2952, by = 295)) +
  xlab("Metric Tons of Green House Gas Emissions") +
  ylab("Building Type") +
  theme(axis.text.x = element_text(angle = 45,  hjust=1)) 
```

Three building type's distributions of emissions jump out as particularly high - Wholesale Club/Supercenter, Prison/Incarceration, and Other - Utility. It is unclear what the latter references. Regarding prison, it seems fairly straightforward that a compound filled with many, many people and complex security systems would have high energy usage. The Club/Supercenter building is perhaps most interesting when considered as a pair along with Ice/Curling Rink - another fairly high distribution. It may be the case that large cooling efforts in the city are particularly bad for the environment.

Before drawing any concrete conclusions, we should, however, point out some issues with our data. This is a data set for 1 year (2019), so there is a risk that it was an aberrant year. Perhaps more importantly, as a reminder, these are only buildings covered by Local Law 84, which is based on square footage thresholds. This means that we are likely only considering the worst emissions buildings throughout the city. It's possible that our understanding of the locales and building types most responsible for emissions would shift if we had a more complete picture.

If we were to estimate New York's building overall, though, we may be somewhat surprised by the results. We consider the following:

First - as Local Law 84 separates our dataset based on square footage, we check whether this has a significant role in GHG emissions:

```{r echo = F}

ggplot(filter(df_build_energy, ghg %in% 0:2952 & building_area < 1000000 & `DOF Gross Floor Area (ft²)` < 1000000), aes(x = `DOF Gross Floor Area (ft²)`, y = ghg)) +
  geom_point() +
  xlab("Total Square Footage") +
  ylab("Metric Tons of GHG Emissions") +
  scale_y_continuous(label = comma) +
  ggtitle("Square Footage - GHG Emissions Relationship")
```

While some zero values may skew the overall picutre, there does appear to be a generally positive correlation between the two. As such, in order to estimate total emissions, we take the sum of all documented GHG emissions by the the sum of all of documented square footage - this gives us a metric of GHG emissions per square foot. The calculation gives about 0.0056 metric tons of GHG emissions per square foot.

Next, we apply this to the total square footage documented in land use data set. This dataset (with roughly 30 times as many buildings as the energy use dataset) has 5,584,887,007 total square feet documented in New York City. This comes out to a grand total of an estimate 31,099,387 metric tons of GHG emissions from New York City in 2019. To put this number into context, Google Sustainability Initiative estimates that in the same year [San Francisco emitted 4,360,000 metric tons of GHG](https://insights.sustainability.google/places/ChIJIQBpAG2ahYAR_6128GcTUEo/buildings?ty=2019). Obviously, New York's number is much larger. However, New York's population is also [about 9.46 times larger than San Francisco's](https://www.census.gov/quickfacts/fact/table/sanfranciscocitycalifornia,newyorkcitynewyork/PST045219). So, while our estimated(!) GHG emissions are 7.13 times larger San Francisco's, on a per person basis each of us actually responsibility for about 75.4% of the building emissions of one San Franciscan.

Having taken stock of the current state of New York's environmental impact, we shift our focus towards potential solutions. 

We

Given the importance of transportation emissions statewide, and the decrease in its importance in a less car-dependent area, we begin with a consideration of on-road vehicles. Specifically, we review electric vehicles.

To begin, we compare the United States' overall EV adoption rate to the rest of the world.:

### global electric car sales

# TODO beautfiy/diff type of graph?
# TODO maybe do % increase each year?
```{r echo = F}
global_electric_car_sales_df <- global_electric_car_sales_data %>%
  select(x, china, usa, europe, japan) %>%
  gather(key = "variable", value = "value", -x)

ggplot(global_electric_car_sales_df, aes(x = x, y = value, fill = variable)) + 
  geom_bar(stat="identity", right = T) +
  scale_fill_discrete(name = "Country", labels = c("China", "Europe", "Japan", "United States"))+
  xlab("Year") +
  ylab("IDK what these are") +
  ggtitle("Electric Vehicle Purchases Over Time") +
  scale_x_continuous(breaks = seq(2010, 2020, 1)) +
  xlab("Year")

```

While the volume of EVs purchased over time is mostly a function of population size, rate of growth does not necessarily need to be. And the United States is clearly lacking in this area (especially as compared to China).

In order to understand if New York is a part of this trend or a bright spot, we consider the state's current rebate program for Electric Vehicles. 
```{r echo = F}
# rebates started in 2017
energy_program_participants = energy_programs_data %>% 
  filter(year > 2016 & year < 2021 
         & program_name == 'Electric Vehicles - Rebate'
         & reporting_period != '2020 Q4') %>%
  select(reporting_period,
         direct_participants_counts_commitments_planned_to_date,
         direct_participants_counts_acquired_to_date) %>%
  gather(key = "variable", value = "value", -reporting_period)

ggplot(energy_program_participants, 
       aes(x = reporting_period,
           y = value,
           fill = variable)) + 
  geom_bar(stat = "identity",position="dodge") +
  theme(legend.title = element_blank(), axis.text.x = element_text(angle = 90)) +
  scale_fill_discrete(labels = c(
    direct_participants_counts_acquired_to_date="Participants Acquired",
    direct_participants_counts_commitments_planned_to_date="Participants Planned"))+
  ggtitle("EV Cumulative Sales - Planned vs. Actual") +
  scale_y_continuous(label = comma) +
  ylab("Electric Vehicles Sold with Rebate to Date") +
  xlab("Reporting Period")
```
Similar to the country at large, we see slow adoption, even with the rebate. However, whether this is due to lack of interest is difficult to say. Beginning in late 2018, the number of vehicles purchased via the rebate has consistently outperformed expectations, and the rules of the rebate are such that not all people above this planned threshold will receive it. This could suggest that there is perhaps not an overwhelming natural desire EVs, but a healthy one for EVs with a rebate. An increased cap could potentially spur more major growth in this area.


Also of note is the increase in emissions reductions via the program:

```{r echo = F}
energy_programs_data_df = energy_programs_data %>% 
  filter(year > 2016 & year < 2021 
         & reporting_period != '2020 Q4'
         & program_name == 'Electric Vehicles - Rebate') %>%
  select(reporting_period,
         direct_gross_lifetime_co2e_emission_reductions_metric_tons_commitments_planned_to_date,
         direct_gross_lifetime_co2e_emission_reductions_metric_tons_acquired_to_date) %>%
  gather(key = "variable", value = "value", -reporting_period)

ggplot(energy_programs_data_df, 
       aes(x = reporting_period,
           y = value,
           fill = variable)) + 
  geom_bar(stat = "identity",position="dodge") +
  theme(legend.title = element_blank(), axis.text.x = element_text(angle = 90)) +
  scale_fill_discrete(labels = c(
    direct_gross_lifetime_co2e_emission_reductions_metric_tons_acquired_to_date="Actual Reductions",
    direct_gross_lifetime_co2e_emission_reductions_metric_tons_commitments_planned_to_date="Planned Reduction")) +
  xlab("Reporting Period") +
  ylab(TeX("Metric Tons of $\\CO_2$")) +
  ggtitle(TeX("Resulting $\\CO_2$ Reductions - Planned vs. Actual"))+
  scale_y_continuous(label = comma)
```

Similarly to the rebate participants, since late 2018 actual emissions reductions have exceeded planeed reductions. Of extra note, however, is that actually reductions appear to exceed planned by a larger margin that rebate participation. This suggests that, while access to the rebate may be a motivating factor, a desire the lowest emission vehicles available may be as well.


Cumualtive rebate $
```{r echo = F}
ggplot(clean_rebate_data_by_quarter, 
       aes(x = factor(year_quarter),
           y = cumulative_rebate_amount)) + 
  geom_bar(stat = "identity") +
  theme(legend.title = element_blank(), axis.text.x = element_text(angle = 90)) +
  ylab("Total Rebates Given to Date") +
  xlab("Reporting Period") +
  scale_y_continuous(label = dollar_format()) +
  ggtitle("Cumulative Rebates")
```

I DON'T HAVE COMMENTARY FOR THIS/I THINK IT'S BASICALLY THE SAME AS THE ACUTAL VS. PLANNED LARRY

quarter rebate $
```{r echo = F}
ggplot(clean_rebate_data, 
       aes(x = factor(year_quarter),
           y = rebate_amount_usd_)) + 
  geom_bar(stat = "identity", aes(group=year_quarter)) +
  theme(legend.title = element_blank(), axis.text.x = element_text(angle = 90)) +
  scale_y_continuous(label = dollar_format()) +
  ylab("Rebate Amount") +
  xlab("Reporting Period") +
  ggtitle("Rebates Given by Quarter")
```
I DON'T HAVE COMMENTARY FOR THIS

Zooming out, we consider rebate amounts each year of the program:
```{r echo = F}
ggplot(clean_rebate_data, 
       aes(x = year,
           y = rebate_amount_usd_)) + 
  geom_bar(stat = "identity", aes(group=year)) +
  theme(legend.title = element_blank(), axis.text.x = element_text(angle = 90))+
  scale_y_continuous(label = dollar_format()) +
  ylab("Rebate Amount") +
  xlab("Year") +
  ggtitle("Rebates Given by Year")
```
We see a somewhat linear growth pattern. While a simple line would certainly not fit the data perfectly, it does fit well enough for rough estimates of potential future usage.

Fitting a regression line to the predict rebate usage moving forward, we see that the program will run out between 2021 Q4 and 2022 Q4 (at the intersection of the red line):
```{r echo = F}
clean_rebate_regression_data = select(clean_rebate_data_by_quarter,
                                      cumulative_rebate_amount, 
                                      year_quarter)
clean_rebate_regression_data$quarter_as_int <- seq.int(nrow(clean_rebate_regression_data))
# y is quarters out from 1 = 2017 Q1
# lm_rebate = lm(quarter_as_int ~ cumulative_rebate_amount, data = clean_rebate_regression_data)
# slope = lm_rebate$coefficients['cumulative_rebate_amount']
# 
# new = data.frame(cumulative_rebate_amount = c(60000000))
# quarter_estimate = round(predict(lm_rebate, new))
# y is $
lm_rebate = lm(cumulative_rebate_amount ~ quarter_as_int, data = clean_rebate_regression_data)
slope = lm_rebate$coefficients['quarter_as_int']
quarters_to_predict = c(18:30)
new = data.frame(quarter_as_int = quarters_to_predict)
dollar_estimate = data.frame(cumulative_rebate_amount = round(predict(lm_rebate, new)))
dollar_estimate$quarter_as_int = quarters_to_predict
# fill in years
start = as.Date(as.yearqtr("2021 Q2"))
end = as.Date(((length(quarters_to_predict) * .25) - .25) + as.yearqtr("2021 Q2"))
fill_in_quarters <- as.yearqtr(seq.Date(from=start, to = end, by="quarter"), format = "%Y-%m-%d")
dollar_estimate$year_quarter = fill_in_quarters
final_reg <- rbind(clean_rebate_regression_data, dollar_estimate)
# TODO for interactive piece: take a # to cut off cum rebate at
```

```{r echo = F}
ggplot(final_reg,
       aes(x=factor(year_quarter),
           y=cumulative_rebate_amount)
       ) + 
  geom_bar(stat = "identity") +
  geom_hline(yintercept = 60000000, color = "red", linetype="dotted") +
  theme(legend.title = element_blank(), axis.text.x = element_text(angle = 90)) +
  ylab("Total Predicted Rebates to Date") +
  xlab("Reporting Period") +
  scale_y_continuous(label = dollar_format()) +
  ggtitle("Predicted Cumulative Rebates")
```
This suggests that current policy could be holding the state back from a more environmentally friendly endpoint. Perhaps increasing the rebate could make this possible.
